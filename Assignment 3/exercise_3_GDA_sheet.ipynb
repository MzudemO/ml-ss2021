{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Machine Learning SoSe21 Practice Class\n",
    "\n",
    "Dr. Timo Baumann, Dr. Özge Alaçam, Björn Sygo <br>\n",
    "Email: baumann@informatik.uni-hamburg.de, alacam@informatik.uni-hamburg.de, 6sygo@informatik.uni-hamburg.de\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 3\n",
    "**Description:** Implement gaussian discriminant analysis on the provided images <br>\n",
    "**Deadline:** Saturday, 15. May 2021, 23:59 <br>\n",
    "**Working together:** You can work in pairs or triples but no larger teams are allowed. <br>\n",
    "&emsp;&emsp;&emsp; &emsp; &emsp; &emsp; &emsp; Please adhere to the honor code discussed in class. <br>\n",
    "&emsp;&emsp;&emsp; &emsp; &emsp; &emsp; &emsp; All members of the team must get involved in understanding and coding the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Submission: \n",
    "**Put your names here**\n",
    "\n",
    "*Also put high-level comments that should be read before looking at your code and results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Goal\n",
    "\n",
    "1. The goal of this exercise is to build a classifier for real-life data (images).\n",
    "2. You will derive features of the images and then use GDA for classification, i.e., you compute the probability of each image being sampled from one of the classes $j$ (in our case $j \\in \\{\\textrm{no_mask}, \\textrm{mask}\\}$). This probability can be calculated with <br>\n",
    "$p(y=j|x)= \\frac{p(x|y=j)p(y=j)}{p(x|y=j)p(y=j)+p(x|y \\neq j)p(y \\neq j)}$ <br>\n",
    "where <br>\n",
    "$p(x|y=j)=\\frac{1}{(2 \\pi)^{\\frac{n}{2}}|\\Sigma|^{\\frac{1}{2}}}e^{-\\frac{1}{2}(x-\\mu_j)^T \\Sigma^{-1} (x-\\mu_j)}$ <br>\n",
    "and the prior probability $p(y=j)=1-\\Phi$ (depending on the dataset).\n",
    "3. For later classification, you compute for each class the probability that the image is a sample of it and choose the class with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the images\n",
    "\n",
    "**Task 1** (15%): Load the images and represent them so that you can work with them.\n",
    "\n",
    "The dataset contains identically sized images of people with and without facemasks and the goal is to classify if an image contains a person wearing a facemask or not. Note that some images have 3 colors, some also have an alpha channel which you should probably ignore.\n",
    "\n",
    "When the images are loaded, they are represented as a 32x32x3 matrix. One of the 3 layers of the matrix is for the red (R) value, one for the \n",
    "green (G) value and one for the blue (B) value. The image itself is created by taking the values of each of theses 3 matrices at (i,j) to create the \n",
    "pixel of the image at spot (i,j). Each of the values can be in range of 0-255.\n",
    "\n",
    "First, you should load in the images (see zip files). There are two versions of the dataset, a small subsample which contains 40 images for each of the two classes, and the large full dataset (with imbalanced classes). There are multiple libraries for image representation. Try PIL or google around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40\n32\n32\n3\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image as im\n",
    "import glob\n",
    "\n",
    "def load_imgs_to_array(path):\n",
    "    \n",
    "    imgs = []\n",
    "    for imgpath in glob.iglob(path + \"*\"):\n",
    "        img=im.open(imgpath)\n",
    "        image = []\n",
    "        for row in range(img.height):\n",
    "            pixels = []\n",
    "            for column in range(img.width):\n",
    "                pixels.append(img.getpixel((row, column))[:3])\n",
    "            #print(row)\n",
    "            image.append(pixels)\n",
    "        imgs.append(image)\n",
    "    return imgs\n",
    "\n",
    "\n",
    "#mask_path = \"subset/mask/\"\n",
    "#nomask_path = \"subset/no_mask/\"\n",
    "\n",
    "mask_imgs = load_imgs_to_array(\"subset/mask/\")\n",
    "nomask_imgs = load_imgs_to_array(\"subset/no_mask/\")\n",
    "\n",
    "print(len(mask_imgs)) #Anzahl Bilder\n",
    "#print(len(nomask_imgs))\n",
    "print(len(mask_imgs[0])) #Anzahl Reihen\n",
    "print(len(mask_imgs[0][0])) #Anzahl Pixel pro Reihe\n",
    "print(len(mask_imgs[0][0][0])) #Anzahl Farbkanäle pro Pixel\n",
    "#mask_imgs[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Obtain feature vectors\n",
    "\n",
    "**Task 2** (15%): Build a feature vector and represent each image by its corresponding feature vector.\n",
    "\n",
    "For Gaussian Discriminant Analysis, the images should be represented as feature vectors. A feature vector consists of different features of the image, for example mean or variance of pixel values, of color channels, number of \"blue\" pixels, etc. Be creative. The more discriminative your features, the better your classifier will perform.\n",
    "\n",
    "Your feature vector should contain at least 5 different features. (Note: your code below should also work with more or fewer features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[167.3876953125, 160.5908203125, 164.33203125]\n[82.3959754032754, 83.03947405704614, 84.59746776425418]\n"
     ]
    }
   ],
   "source": [
    "image = mask_imgs[0]\n",
    "pixel_count = len(image) * len(image[0])\n",
    "\n",
    "\n",
    "def meanValues(image):\n",
    "    mean_image = [0, 0, 0]\n",
    "    for row in image:\n",
    "        for pixel in row:\n",
    "            for index, chan in enumerate(pixel):\n",
    "                mean_image[index] += chan\n",
    "\n",
    "\n",
    "    \n",
    "    for index, channel in enumerate(mean_image):\n",
    "        mean_image[index] /= pixel_count\n",
    "    return mean_image\n",
    "\n",
    "print(meanValues(image))\n",
    "\n",
    "def sigmaValues(image):\n",
    "    sigma_image = [0, 0, 0]\n",
    "    mean_image = meanValues(image)\n",
    "    for row in image:\n",
    "        for pixel in row:\n",
    "            for index, chan in enumerate(pixel):\n",
    "                sigma_image[index] += (chan - mean_image[index])**2\n",
    "\n",
    "\n",
    "    \n",
    "    for index, channel in enumerate(sigma_image):\n",
    "        sigma_image[index] = (sigma_image[index] / pixel_count) ** (1/2)\n",
    "    return sigma_image\n",
    "\n",
    "print(sigmaValues(image))\n",
    "\n",
    "\n",
    "def meanValuesAllImages(images):\n",
    "    new_images = []\n",
    "    for image in images:\n",
    "        new_images.append(meanValues(image))\n",
    "    return new_images\n",
    "\n",
    "#print(meanValuesAllImages(mask_imgs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5.304687500000002, 41.70673828124999, 75.23935546874999]\n278\n88\n302\n661\n[88, 661, 167.3876953125, 160.5908203125, 164.33203125, 82.3959754032754, 83.03947405704614, 84.59746776425418, 8.048046875, 75.39179687500003, 140.95878906250002]\n"
     ]
    }
   ],
   "source": [
    "## maskfilter mean\n",
    "maskFilter = [\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "[0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0.5, 0.5, 0],\n",
    "[0, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0.5, 0.5, 0],\n",
    "[0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "image = nomask_imgs[3]\n",
    "\n",
    "def meanValuesFiltered(image, filter):\n",
    "    mean_image = [0, 0, 0]\n",
    "    for row in image:\n",
    "        for i, pixel in enumerate(row):\n",
    "            for j, chan in enumerate(pixel):\n",
    "                mean_image[j] += chan*filter[i][j]\n",
    "\n",
    "\n",
    "    \n",
    "    for index, channel in enumerate(mean_image):\n",
    "        mean_image[index] /= pixel_count\n",
    "    return mean_image\n",
    "\n",
    "print(meanValuesFiltered(image, maskFilter))\n",
    "\n",
    "blue_min = [0, 0, 100]\n",
    "blue_max = [180, 180, 255]\n",
    "\n",
    "\n",
    "white_min = [128,128,128]\n",
    "white_max = [255,255,255]\n",
    "\n",
    "def countColorValues(image, color_min, color_max):\n",
    "    count = 0\n",
    "    for row in image:\n",
    "        for pixel in row:\n",
    "            is_in_range = True\n",
    "            for index in range(len(pixel)):\n",
    "                if not color_min[index] <= pixel[index] <= color_max[index]:\n",
    "                    is_in_range = False\n",
    "            count += is_in_range\n",
    "    return count\n",
    "\n",
    "print(countColorValues(nomask_imgs[0], blue_min, blue_max))\n",
    "print(countColorValues(mask_imgs[0], blue_min, blue_max))\n",
    "\n",
    "print(countColorValues(nomask_imgs[0], white_min, white_max))\n",
    "print(countColorValues(mask_imgs[0], white_min, white_max))\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "def featureVector(image):\n",
    "    blue_value = countColorValues(image, blue_min, blue_max)\n",
    "    white_value = countColorValues(image, white_min, white_max)\n",
    "    mean = meanValues(image)\n",
    "    sigma = sigmaValues(image)\n",
    "    mask_filter = meanValuesFiltered(image, maskFilter)\n",
    "    return [blue_value, white_value] + mean + sigma + mask_filter\n",
    "\n",
    "print(featureVector(mask_imgs[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initialize your parameters\n",
    "\n",
    "**Task 3** (5%):  Initialize your parameters for the GDA algorithm.\n",
    "\n",
    "For the discriminant analysis, you will need to estimate your parameters $\\Phi, \\mu_0, \\mu_1, \\Sigma$.\n",
    "\n",
    "For this, you will need to initialize them first. You can just initalize them with 0, but you should consider their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n0\n"
     ]
    }
   ],
   "source": [
    "test_feature_vector = featureVector(nomask_imgs[0])\n",
    "\n",
    "mew_zero = [0 for _ in test_feature_vector]\n",
    "mew_one = [0 for _ in test_feature_vector]\n",
    "print(mew_one)\n",
    "\n",
    "covar_matrix = [[0 for _ in test_feature_vector] for _ in test_feature_vector]\n",
    "print(covar_matrix)\n",
    "\n",
    "#phi = len(mask_imgs)/(len(mask_imgs)+(len(nomask_imgs)))\n",
    "phi = 0\n",
    "print(phi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Implement Gaussian Discriminant analysis\n",
    "\n",
    "**Task 4** (35%):  Implement the Gaussian Discriminant Analysis algorithm.\n",
    "\n",
    "Now you can use the GDA algorithm to find an estimation for the correct parameters to classify the images later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5\n[805.0000000000002, 1326.4999999999998, 586.1732421874999, 481.3052734375, 426.1847656250001, 211.9522073347637, 199.15042902360557, 192.48956847348794, 24.38664062500001, 197.98219726562505, 315.635390625]\n[495.4499999999999, 1172.3000000000002, 319.11196289062497, 310.45971679687506, 304.07416992187495, 107.996632934554, 120.7989642292949, 130.97023631184328, 12.520991210937497, 134.67083984375003, 245.93852050781248]\n"
     ]
    }
   ],
   "source": [
    "def calcPhi(mask_images, nomask_images):\n",
    "    phi = len(mask_imgs)/(len(mask_imgs)+(len(nomask_imgs)))\n",
    "    return phi\n",
    "\n",
    "def calcMew(images, mew):\n",
    "    count_pictures = len(images)\n",
    "    for image in images:\n",
    "        temp_FV = featureVector(image)\n",
    "        for index, feature in enumerate(temp_FV):\n",
    "           mew[index] += feature / count_pictures \n",
    "    return mew\n",
    "\n",
    "print(calcPhi(mask_imgs, nomask_imgs))\n",
    "print(calcMew(nomask_imgs, mew_zero))\n",
    "print(calcMew(mask_imgs, mew_one))\n",
    "\n",
    "def calcSigma()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Classify with the Bayes rule\n",
    "**Task 5** (10%): Use the Bayes rule to check how many images were correctly classified.\n",
    "\n",
    "Now that you have estimated your parameters, you can use the Bayes rule to classify the images. You then can evaluate how many of the images were correctly classified and try again with different features if the results weren't good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross-validation\n",
    "\n",
    "**Task 6** (10%): Implement 10-fold cross-validation and report the quality of your results in terms of accuracy and f-score.\n",
    "\n",
    "You have so far trained and tested your classifier on the same data. This does not tell us much about the true performance on unseen data. \n",
    "Instead, you should now randomly split your data into _k_ folds of equal size. you then train your model _k_ times, using all but the _k_'th fold for training and the _k_'th fold for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature importance\n",
    "\n",
    "**Task 7** (10%): Experiment with the features: how well does the classifier perform with individual features, what is the additional value of the second best feature in addition to the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Report Submission\n",
    "\n",
    "Prepare a report of your solution as a commented Jupyter notebook (using markdown for your results and comments); include figures and results.\n",
    "If you must, you can also upload a PDF document with the report annexed with your Python code.\n",
    "\n",
    "Upload your report file to the Machine Learning Moodle Course page. Please make sure that your submission team corresponds to the team's Moodle group that you're in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}