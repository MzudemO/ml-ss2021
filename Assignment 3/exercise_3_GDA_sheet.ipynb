{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Machine Learning SoSe21 Practice Class\n",
    "\n",
    "Dr. Timo Baumann, Dr. Özge Alaçam, Björn Sygo <br>\n",
    "Email: baumann@informatik.uni-hamburg.de, alacam@informatik.uni-hamburg.de, 6sygo@informatik.uni-hamburg.de\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercise 3\n",
    "**Description:** Implement gaussian discriminant analysis on the provided images <br>\n",
    "**Deadline:** Saturday, 15. May 2021, 23:59 <br>\n",
    "**Working together:** You can work in pairs or triples but no larger teams are allowed. <br>\n",
    "&emsp;&emsp;&emsp; &emsp; &emsp; &emsp; &emsp; Please adhere to the honor code discussed in class. <br>\n",
    "&emsp;&emsp;&emsp; &emsp; &emsp; &emsp; &emsp; All members of the team must get involved in understanding and coding the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Submission: \n",
    "**Christoph Brauer, Linus Geewe, Moritz Lahann**\n",
    "\n",
    "*Also put high-level comments that should be read before looking at your code and results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Goal\n",
    "\n",
    "1. The goal of this exercise is to build a classifier for real-life data (images).\n",
    "2. You will derive features of the images and then use GDA for classification, i.e., you compute the probability of each image being sampled from one of the classes $j$ (in our case $j \\in \\{\\textrm{no_mask}, \\textrm{mask}\\}$). This probability can be calculated with <br>\n",
    "$p(y=j|x)= \\frac{p(x|y=j)p(y=j)}{p(x|y=j)p(y=j)+p(x|y \\neq j)p(y \\neq j)}$ <br>\n",
    "where <br>\n",
    "$p(x|y=j)=\\frac{1}{(2 \\pi)^{\\frac{n}{2}}|\\Sigma|^{\\frac{1}{2}}}e^{-\\frac{1}{2}(x-\\mu_j)^T \\Sigma^{-1} (x-\\mu_j)}$ <br>\n",
    "and the prior probability $p(y=j)=1-\\Phi$ (depending on the dataset).\n",
    "3. For later classification, you compute for each class the probability that the image is a sample of it and choose the class with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the images\n",
    "\n",
    "**Task 1** (15%): Load the images and represent them so that you can work with them.\n",
    "\n",
    "The dataset contains identically sized images of people with and without facemasks and the goal is to classify if an image contains a person wearing a facemask or not. Note that some images have 3 colors, some also have an alpha channel which you should probably ignore.\n",
    "\n",
    "When the images are loaded, they are represented as a 32x32x3 matrix. One of the 3 layers of the matrix is for the red (R) value, one for the \n",
    "green (G) value and one for the blue (B) value. The image itself is created by taking the values of each of theses 3 matrices at (i,j) to create the \n",
    "pixel of the image at spot (i,j). Each of the values can be in range of 0-255.\n",
    "\n",
    "First, you should load in the images (see zip files). There are two versions of the dataset, a small subsample which contains 40 images for each of the two classes, and the large full dataset (with imbalanced classes). There are multiple libraries for image representation. Try PIL or google around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40\n32\n32\n3\n40\n32\n32\n3\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image as im\n",
    "import glob\n",
    "import math\n",
    "\n",
    "def load_imgs_to_array(path):\n",
    "    \n",
    "    imgs = []\n",
    "    for imgpath in glob.iglob(path + \"*\"):\n",
    "        img=im.open(imgpath)\n",
    "        image = []\n",
    "        for row in range(img.height):\n",
    "            pixels = []\n",
    "            for column in range(img.width):\n",
    "                pixels.append(img.getpixel((row, column))[:3])\n",
    "            #print(row)\n",
    "            image.append(pixels)\n",
    "        imgs.append(image)\n",
    "    return imgs\n",
    "\n",
    "def load_imgs_numpy(path):\n",
    "    imgs = []\n",
    "    for index, imgpath in enumerate(glob.iglob(path + \"*\")):\n",
    "        img = im.open(imgpath)\n",
    "        imgs.append(np.array(img)[:, :, :3])\n",
    "    return np.array(imgs)    \n",
    "\n",
    "#mask_path = \"subset/mask/\"\n",
    "#nomask_path = \"subset/no_mask/\"\n",
    "\n",
    "mask_imgs = load_imgs_to_array(\"subset/mask/\")\n",
    "nomask_imgs = load_imgs_to_array(\"subset/no_mask/\")\n",
    "\n",
    "print(len(mask_imgs)) #Anzahl Bilder\n",
    "#print(len(nomask_imgs))\n",
    "print(len(mask_imgs[0])) #Anzahl Reihen\n",
    "print(len(mask_imgs[0][0])) #Anzahl Pixel pro Reihe\n",
    "print(len(mask_imgs[0][0][0])) #Anzahl Farbkanäle pro Pixel\n",
    "\n",
    "mask_imgs = load_imgs_numpy(\"subset/mask/\")\n",
    "nomask_imgs = load_imgs_numpy(\"subset/no_mask/\")\n",
    "\n",
    "print(len(mask_imgs)) #Anzahl Bilder\n",
    "#print(len(nomask_imgs))\n",
    "print(len(mask_imgs[0])) #Anzahl Reihen\n",
    "print(len(mask_imgs[0][0])) #Anzahl Pixel pro Reihe\n",
    "print(len(mask_imgs[0][0][0])) #Anzahl Farbkanäle pro Pixel\n",
    "im.fromarray(mask_imgs[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Obtain feature vectors\n",
    "\n",
    "**Task 2** (15%): Build a feature vector and represent each image by its corresponding feature vector.\n",
    "\n",
    "For Gaussian Discriminant Analysis, the images should be represented as feature vectors. A feature vector consists of different features of the image, for example mean or variance of pixel values, of color channels, number of \"blue\" pixels, etc. Be creative. The more discriminative your features, the better your classifier will perform.\n",
    "\n",
    "Your feature vector should contain at least 5 different features. (Note: your code below should also work with more or fewer features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[137.1005859375, 124.8974609375, 120.0791015625]\n[137.10058594 124.89746094 120.07910156]\n[53.051554374322315, 54.79423720660013, 54.675468254787816]\n[53.05155437 54.79423721 54.67546825]\n"
     ]
    }
   ],
   "source": [
    "image = mask_imgs[0]\n",
    "pixel_count = len(image) * len(image[0])\n",
    "\n",
    "\n",
    "def meanValues(image):\n",
    "    mean_image = [0, 0, 0]\n",
    "    for row in image:\n",
    "        for pixel in row:\n",
    "            for index, chan in enumerate(pixel):\n",
    "                mean_image[index] += chan\n",
    "\n",
    "\n",
    "    \n",
    "    for index, channel in enumerate(mean_image):\n",
    "        mean_image[index] /= pixel_count\n",
    "    return mean_image\n",
    "\n",
    "def mean_numpy(image):\n",
    "    return np.mean(image, (0, 1))\n",
    "\n",
    "print(meanValues(image))\n",
    "\n",
    "print(mean_numpy(image))\n",
    "\n",
    "def sigmaValues(image):\n",
    "    sigma_image = [0, 0, 0]\n",
    "    mean_image = meanValues(image)\n",
    "    for row in image:\n",
    "        for pixel in row:\n",
    "            for index, chan in enumerate(pixel):\n",
    "                sigma_image[index] += (chan - mean_image[index])**2\n",
    "\n",
    "\n",
    "    \n",
    "    for index, channel in enumerate(sigma_image):\n",
    "        sigma_image[index] = (sigma_image[index] / pixel_count) ** (1/2)\n",
    "    return sigma_image\n",
    "\n",
    "def variance_numpy(image):\n",
    "    return np.std(image, (0, 1))\n",
    "\n",
    "print(sigmaValues(image))\n",
    "\n",
    "print(variance_numpy(image))\n",
    "\n",
    "def meanValuesAllImages(images):\n",
    "    new_images = []\n",
    "    for image in images:\n",
    "        new_images.append(meanValues(image))\n",
    "    return new_images\n",
    "\n",
    "#print(meanValuesAllImages(mask_imgs))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9.074414062500002, 50.64560546874999, 75.47080078125005]\n80\n188\n451\n455\n[188, 455, 137.1005859375, 124.8974609375, 120.0791015625, 53.051554374322315, 54.79423720660013, 54.675468254787816, 6.504882812499999, 53.69960937500002, 92.67578125000003]\n[188.         455.         137.10058594 124.89746094 120.07910156\n  53.05155437  54.79423721  54.67546825  99.76337891  93.5296875\n  90.86425781]\n(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "## maskfilter mean\n",
    "maskFilter = [\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "[0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0],\n",
    "[0, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0.5, 0.5, 0],\n",
    "[0, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0.5, 0.5, 0],\n",
    "[0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0],\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "image = nomask_imgs[3]\n",
    "\n",
    "def meanValuesFiltered(image, filter):\n",
    "    mean_image = [0, 0, 0]\n",
    "    for row in image:\n",
    "        for i, pixel in enumerate(row):\n",
    "            for j, chan in enumerate(pixel):\n",
    "                mean_image[j] += chan*filter[i][j]\n",
    "\n",
    "\n",
    "    \n",
    "    for index, channel in enumerate(mean_image):\n",
    "        mean_image[index] /= pixel_count\n",
    "    return mean_image\n",
    "\n",
    "def masked_mean_numpy(image, mask):\n",
    "    mask = np.array([np.array(row) for row in mask])\n",
    "    masked_image = image * np.stack((mask, mask, mask), 2)\n",
    "\n",
    "    return mean_numpy(masked_image)\n",
    "\n",
    "print(meanValuesFiltered(image, maskFilter))\n",
    "\n",
    "blue_min = [0, 0, 100]\n",
    "blue_max = [180, 180, 255]\n",
    "\n",
    "\n",
    "white_min = [128,128,128]\n",
    "white_max = [255,255,255]\n",
    "\n",
    "def countColorValues(image, color_min, color_max):\n",
    "    count = 0\n",
    "    for row in image:\n",
    "        for pixel in row:\n",
    "            is_in_range = True\n",
    "            for index in range(len(pixel)):\n",
    "                if not color_min[index] <= pixel[index] <= color_max[index]:\n",
    "                    is_in_range = False\n",
    "            count += is_in_range\n",
    "    return count\n",
    "\n",
    "print(countColorValues(nomask_imgs[0], blue_min, blue_max))\n",
    "print(countColorValues(mask_imgs[0], blue_min, blue_max))\n",
    "\n",
    "print(countColorValues(nomask_imgs[0], white_min, white_max))\n",
    "print(countColorValues(mask_imgs[0], white_min, white_max))\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "def featureVector(image):\n",
    "    blue_value = countColorValues(image, blue_min, blue_max)\n",
    "    white_value = countColorValues(image, white_min, white_max)\n",
    "    mean = meanValues(image)\n",
    "    sigma = sigmaValues(image)\n",
    "    mask_filter = meanValuesFiltered(image, maskFilter)\n",
    "    return [blue_value, white_value] + mean + sigma + mask_filter\n",
    "\n",
    "def fv_numpy(image):\n",
    "    blue_value = countColorValues(image, blue_min, blue_max)\n",
    "    white_value = countColorValues(image, white_min, white_max)\n",
    "    mean = mean_numpy(image)\n",
    "    sigma = variance_numpy(image)\n",
    "    mask_filter = masked_mean_numpy(image, maskFilter)\n",
    "    return np.concatenate((np.array([blue_value, white_value]), mean, sigma, mask_filter)).flatten()\n",
    "\n",
    "print(featureVector(mask_imgs[0]))\n",
    "\n",
    "print(fv_numpy(mask_imgs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initialize your parameters\n",
    "\n",
    "**Task 3** (5%):  Initialize your parameters for the GDA algorithm.\n",
    "\n",
    "For the discriminant analysis, you will need to estimate your parameters $\\Phi, \\mu_0, \\mu_1, \\Sigma$.\n",
    "\n",
    "For this, you will need to initialize them first. You can just initalize them with 0, but you should consider their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n0\n"
     ]
    }
   ],
   "source": [
    "test_feature_vector = featureVector(nomask_imgs[0])\n",
    "\n",
    "test_fv = fv_numpy(nomask_imgs[0])\n",
    "\n",
    "mew_zero = [0 for _ in test_feature_vector]\n",
    "mew_one = [0 for _ in test_feature_vector]\n",
    "print(mew_one)\n",
    "\n",
    "# our mean vectors have the same dimension as our feature vector (we don't initialize them separately here)\n",
    "mu_initial = np.zeros_like(test_fv)\n",
    "print(mu_initial)\n",
    "\n",
    "# our covariance matrix is a 2D matrix with dimensions n x n (where n: length of mu)\n",
    "covar_matrix = [[0 for _ in test_feature_vector] for _ in test_feature_vector]\n",
    "print(covar_matrix)\n",
    "\n",
    "mu_for_sigma = mu_initial.reshape(1, mu_initial.shape[0])\n",
    "sigma_initial = mu_for_sigma * mu_for_sigma.T\n",
    "print(sigma_initial)\n",
    "\n",
    "# our phi is a scalar value denoting the probability of a test sample having one of two classes \n",
    "phi = 0\n",
    "print(phi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Implement Gaussian Discriminant analysis\n",
    "\n",
    "**Task 4** (35%):  Implement the Gaussian Discriminant Analysis algorithm.\n",
    "\n",
    "Now you can use the GDA algorithm to find an estimation for the correct parameters to classify the images later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5\n",
      "[201.25       331.625      146.54331055 120.32631836 106.54619141\n",
      "  52.98805183  49.78760726  48.12239212   7.28666504  48.40912109\n",
      "  74.6356543 ]\n",
      "[247.725      586.15       159.55598145 155.2298584  152.03708496\n",
      "  53.99831647  60.39948211  65.48511816   7.35682373  66.12480957\n",
      " 116.94914307]\n",
      "[[ 1.40822434e+04 -3.65349500e+03 -1.02186818e+03 -5.28374248e+02\n",
      "  -3.07383255e+02 -6.44844053e+02 -5.52217144e+02 -4.76976215e+02\n",
      "  -2.61853282e+01 -2.60858726e+02 -3.30783952e+02]\n",
      " [-3.65349500e+03  2.81683309e+04  3.52384237e+03  3.28282589e+03\n",
      "   3.14517231e+03  2.64176825e+02  3.39351211e+02  3.40200532e+02\n",
      "   1.66397733e+02  1.31634839e+03  2.21571840e+03]\n",
      " [-1.02186818e+03  3.52384237e+03  6.50365863e+02  5.26148653e+02\n",
      "   4.52834566e+02 -1.53631477e+01  4.27861321e+00  1.28751728e+01\n",
      "   2.78063034e+01  2.08124940e+02  3.10824545e+02]\n",
      " [-5.28374248e+02  3.28282589e+03  5.26148653e+02  4.81151103e+02\n",
      "   4.37053876e+02 -2.82522895e+01  2.88286595e+00  1.41893624e+01\n",
      "   2.38910973e+01  1.84394169e+02  2.86737515e+02]\n",
      " [-3.07383255e+02  3.14517231e+03  4.52834566e+02  4.37053876e+02\n",
      "   4.29413963e+02 -9.19885003e+00  1.84866645e+01  2.89226612e+01\n",
      "   2.10029774e+01  1.65891403e+02  2.79533738e+02]\n",
      " [-6.44844053e+02  2.64176825e+02 -1.53631477e+01 -2.82522895e+01\n",
      "  -9.19885003e+00  1.66521275e+02  1.30683628e+02  1.10973755e+02\n",
      "  -1.47777369e+00  2.74341900e+00  2.64751457e+01]\n",
      " [-5.52217144e+02  3.39351211e+02  4.27861321e+00  2.88286595e+00\n",
      "   1.84866645e+01  1.30683628e+02  1.26482309e+02  1.17937458e+02\n",
      "  -2.70682153e-01  6.20664172e+00  2.51323080e+01]\n",
      " [-4.76976215e+02  3.40200532e+02  1.28751728e+01  1.41893624e+01\n",
      "   2.89226612e+01  1.10973755e+02  1.17937458e+02  1.20591721e+02\n",
      "   2.65450238e-01  6.46787719e+00  2.21978640e+01]\n",
      " [-2.61853282e+01  1.66397733e+02  2.78063034e+01  2.38910973e+01\n",
      "   2.10029774e+01 -1.47777369e+00 -2.70682153e-01  2.65450238e-01\n",
      "   2.23617965e+00  8.31697339e+00  1.18622950e+01]\n",
      " [-2.60858726e+02  1.31634839e+03  2.08124940e+02  1.84394169e+02\n",
      "   1.65891403e+02  2.74341900e+00  6.20664172e+00  6.46787719e+00\n",
      "   8.31697339e+00  7.99641307e+01  1.30343110e+02]\n",
      " [-3.30783952e+02  2.21571840e+03  3.10824545e+02  2.86737515e+02\n",
      "   2.79533738e+02  2.64751457e+01  2.51323080e+01  2.21978640e+01\n",
      "   1.18622950e+01  1.30343110e+02  2.33529330e+02]]\n",
      "True\n",
      "[[ 1.60295561e+04 -1.21211945e+04 -2.47075010e+03 -1.65095995e+03\n",
      "  -1.36891592e+03 -7.24752731e+02 -6.55641386e+02 -5.93169748e+02\n",
      "  -1.96274078e+03 -1.37345387e+03 -1.16558093e+03]\n",
      " [-1.21211945e+04  2.41673342e+04  3.80209400e+03  3.32456954e+03\n",
      "   3.08275036e+03 -1.12327598e+02 -9.80440498e+01 -1.80767328e+02\n",
      "   2.62930952e+03  2.24270160e+03  2.04797841e+03]\n",
      " [-2.47075010e+03  3.80209400e+03  7.74366219e+02  5.98267789e+02\n",
      "   5.16087192e+02 -1.25553767e+01 -7.61181978e+00 -1.05765456e+01\n",
      "   5.39302447e+02  4.06764202e+02  3.46011779e+02]\n",
      " [-1.65095995e+03  3.32456954e+03  5.98267789e+02  5.39322997e+02\n",
      "   4.91100784e+02 -5.73171187e+01 -3.79920695e+01 -3.71261862e+01\n",
      "   4.05891597e+02  3.61790645e+02  3.26271419e+02]\n",
      " [-1.36891592e+03  3.08275036e+03  5.16087192e+02  4.91100784e+02\n",
      "   4.84883669e+02 -3.83392540e+01 -2.38497445e+01 -2.71499760e+01\n",
      "   3.52806426e+02  3.32766351e+02  3.25757627e+02]\n",
      " [-7.24752731e+02 -1.12327598e+02 -1.25553767e+01 -5.73171187e+01\n",
      "  -3.83392540e+01  1.56963206e+02  1.22914077e+02  1.04303784e+02\n",
      "   3.05600417e+01 -6.79411043e+00  4.44100594e+00]\n",
      " [-6.55641386e+02 -9.80440498e+01 -7.61181978e+00 -3.79920695e+01\n",
      "  -2.38497445e+01  1.22914077e+02  1.10975179e+02  9.85700120e+01\n",
      "   3.25273438e+01  9.20524586e+00  1.66886029e+01]\n",
      " [-5.93169748e+02 -1.80767328e+02 -1.05765456e+01 -3.71261862e+01\n",
      "  -2.71499760e+01  1.04303784e+02  9.85700120e+01  9.55840437e+01\n",
      "   2.70127940e+01  9.03567137e+00  1.58814713e+01]\n",
      " [-1.96274078e+03  2.62930952e+03  5.39302447e+02  4.05891597e+02\n",
      "   3.52806426e+02  3.05600417e+01  3.25273438e+01  2.70127940e+01\n",
      "   4.01403614e+02  2.96116376e+02  2.53390678e+02]\n",
      " [-1.37345387e+03  2.24270160e+03  4.06764202e+02  3.61790645e+02\n",
      "   3.32766351e+02 -6.79411043e+00  9.20524586e+00  9.03567137e+00\n",
      "   2.96116376e+02  2.62926416e+02  2.40563438e+02]\n",
      " [-1.16558093e+03  2.04797841e+03  3.46011779e+02  3.26271419e+02\n",
      "   3.25757627e+02  4.44100594e+00  1.66886029e+01  1.58814713e+01\n",
      "   2.53390678e+02  2.40563438e+02  2.39588428e+02]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calcPhi(mask_images, nomask_images):\n",
    "    phi = len(mask_imgs)/(len(mask_imgs)+(len(nomask_imgs)))\n",
    "    return phi\n",
    "\n",
    "def calcMew(images, mew):\n",
    "    count_pictures = len(images)\n",
    "    m = np.zeros(len(mew))\n",
    "    for image in images:\n",
    "        temp_FV = featureVector(image)\n",
    "        m += temp_FV\n",
    "        # for index, feature in enumerate(temp_FV):\n",
    "        #    mew[index] += feature / count_pictures \n",
    "    return m / count_pictures\n",
    "\n",
    "def calc_mu_numpy(images):\n",
    "    fvs = []\n",
    "    for image in images:\n",
    "        fvs.append(fv_numpy(image))\n",
    "    \n",
    "    return np.mean(np.array(fvs), 0)\n",
    "\n",
    "print(calcPhi(mask_imgs, nomask_imgs))\n",
    "print(calcMew(nomask_imgs, mew_zero))\n",
    "print(calcMew(mask_imgs, mew_one))\n",
    "\n",
    "def calcSigma(mask_images, no_mask_images, mew1, mew2):\n",
    "    # m1 = np.array(mew1)\n",
    "    # m2 = np.array(mew2)\n",
    "    return (calcDifference(mask_images, mew1) + calcDifference(no_mask_images, mew2)) / (len(mask_imgs)+len(no_mask_images))\n",
    "\n",
    "def calc_sigma_numpy(mask_images, nomask_images, mu_mask, mu_nomask):\n",
    "    return calc_difference_numpy(mask_images, mu_mask) + calc_difference_numpy(nomask_images, mu_nomask) / (mask_imgs.shape[0] + nomask_imgs.shape[0])\n",
    "\n",
    "def calc_difference_numpy(images, mu):\n",
    "    sigmas = []\n",
    "    for image in images:\n",
    "        fv = fv_numpy(image)\n",
    "        difference_mask = np.reshape(fv - mu, (1, mu.shape[0]))\n",
    "        sigmas.append(difference_mask * difference_mask.T)\n",
    "    return np.mean(np.array(sigmas), 0)\n",
    "\n",
    "   \n",
    "def calcDifference(images, mew):\n",
    "    sigma = np.zeros((mew.shape[0], mew.shape[0]))\n",
    "    for image in images:\n",
    "        tempFV = np.array(featureVector(image))\n",
    "        difference_mask = np.reshape(tempFV - mew, (1, mew.shape[0]))\n",
    "        # print(difference_mask)\n",
    "        sigma += difference_mask * difference_mask.T\n",
    "    return sigma\n",
    "\n",
    "mu_1 = calcMew(mask_imgs, mew_one)\n",
    "mu_2 = calcMew(nomask_imgs, mew_zero)\n",
    "sigma = calcSigma(mask_imgs, nomask_imgs, mu_1, mu_2)\n",
    "print(sigma)\n",
    "# confirm that sigma is symmetric\n",
    "print(np.allclose(sigma, sigma.T, rtol=1e-05, atol=1e-08))\n",
    "\n",
    "mu_mask = calc_mu_numpy(mask_imgs)\n",
    "mu_nomask = calc_mu_numpy(nomask_imgs)\n",
    "sigma = calc_sigma_numpy(mask_imgs, nomask_imgs, mu_mask, mu_nomask)\n",
    "print(sigma)\n",
    "# confirm that sigma is symmetric\n",
    "print(np.allclose(sigma, sigma.T, rtol=1e-05, atol=1e-08))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Classify with the Bayes rule\n",
    "**Task 5** (10%): Use the Bayes rule to check how many images were correctly classified.\n",
    "\n",
    "Now that you have estimated your parameters, you can use the Bayes rule to classify the images. You then can evaluate how many of the images were correctly classified and try again with different features if the results weren't good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(80, 2)\n[array([[[ 72,  82,  71],\n         [115, 116, 106],\n         [ 73,  68,  60],\n         ...,\n         [ 78,  74,  69],\n         [156, 154, 151],\n         [156, 154, 148]],\n\n        [[184, 183, 171],\n         [176, 175, 165],\n         [ 87,  83,  75],\n         ...,\n         [ 72,  67,  61],\n         [160, 156, 148],\n         [171, 167, 157]],\n\n        [[168, 169, 160],\n         [189, 190, 181],\n         [118, 117, 110],\n         ...,\n         [ 81,  75,  69],\n         [184, 178, 167],\n         [196, 191, 179]],\n\n        ...,\n\n        [[ 76,  77,  86],\n         [ 69,  69,  70],\n         [100,  99,  95],\n         ...,\n         [ 58,  58,  61],\n         [ 95,  91,  88],\n         [ 61,  61,  66]],\n\n        [[ 90,  91,  97],\n         [ 55,  56,  59],\n         [ 36,  38,  44],\n         ...,\n         [ 92,  88,  86],\n         [ 51,  52,  59],\n         [ 56,  58,  64]],\n\n        [[148, 146, 143],\n         [ 74,  75,  75],\n         [ 47,  48,  50],\n         ...,\n         [ 70,  69,  73],\n         [ 93,  92,  92],\n         [123, 120, 116]]], dtype=uint8) 1]\n[array([[[ 72,  82,  71],\n         [115, 116, 106],\n         [ 73,  68,  60],\n         ...,\n         [ 78,  74,  69],\n         [156, 154, 151],\n         [156, 154, 148]],\n\n        [[184, 183, 171],\n         [176, 175, 165],\n         [ 87,  83,  75],\n         ...,\n         [ 72,  67,  61],\n         [160, 156, 148],\n         [171, 167, 157]],\n\n        [[168, 169, 160],\n         [189, 190, 181],\n         [118, 117, 110],\n         ...,\n         [ 81,  75,  69],\n         [184, 178, 167],\n         [196, 191, 179]],\n\n        ...,\n\n        [[ 76,  77,  86],\n         [ 69,  69,  70],\n         [100,  99,  95],\n         ...,\n         [ 58,  58,  61],\n         [ 95,  91,  88],\n         [ 61,  61,  66]],\n\n        [[ 90,  91,  97],\n         [ 55,  56,  59],\n         [ 36,  38,  44],\n         ...,\n         [ 92,  88,  86],\n         [ 51,  52,  59],\n         [ 56,  58,  64]],\n\n        [[148, 146, 143],\n         [ 74,  75,  75],\n         [ 47,  48,  50],\n         ...,\n         [ 70,  69,  73],\n         [ 93,  92,  92],\n         [123, 120, 116]]], dtype=uint8) 1]\n441121244.29272854\n[[ -59.725      -131.15        -22.45539551  -30.33239746  -31.9579834\n    -0.94676209   -5.60524491  -10.8096499   -17.51774658  -25.06328857\n   -27.65401367]]\n[[ 1.31855732e+00  1.10174988e+00  6.95320533e+00 -1.86635897e+01\n   7.69639220e+00  1.46055002e-01 -1.20658017e+00  1.75974319e+00\n  -6.41882263e+00  2.42916232e+01 -1.34233224e+01]\n [ 1.10174988e+00  7.54844602e+00  9.60879942e+00 -4.03535454e+01\n   1.90227519e+01  1.16559483e-01 -3.74118812e+00  7.24335137e+00\n  -1.08793626e+01  4.28979890e+01 -2.98599239e+01]\n [ 6.95320533e+00  9.60879942e+00  2.43224587e+02 -7.99298311e+02\n   4.77252268e+02  4.14320808e+00 -4.71923457e+01  4.61690358e+01\n  -2.57519208e+02  9.51056519e+02 -6.20920958e+02]\n [-1.86635897e+01 -4.03535454e+01 -7.99298311e+02  3.09031533e+03\n  -2.00832345e+03 -1.62743649e+01  2.08884792e+02 -2.16927413e+02\n   8.71115595e+02 -3.68517605e+03  2.58044027e+03]\n [ 7.69639220e+00  1.90227519e+01  4.77252268e+02 -2.00832345e+03\n   1.43834478e+03  1.04906007e+01 -1.44602547e+02  1.67692098e+02\n  -5.34787737e+02  2.40961445e+03 -1.82566470e+03]\n [ 1.46055002e-01  1.16559483e-01  4.14320808e+00 -1.62743649e+01\n   1.04906007e+01  1.63904215e-01 -1.73330853e+00  1.48724953e+00\n  -4.87577959e+00  2.11319352e+01 -1.44031168e+01]\n [-1.20658017e+00 -3.74118812e+00 -4.71923457e+01  2.08884792e+02\n  -1.44602547e+02 -1.73330853e+00  2.46399373e+01 -2.82841181e+01\n   5.51933577e+01 -2.58639093e+02  1.90401649e+02]\n [ 1.75974319e+00  7.24335137e+00  4.61690358e+01 -2.16927413e+02\n   1.67692098e+02  1.48724953e+00 -2.82841181e+01  4.35971299e+01\n  -5.46444348e+01  2.64753928e+02 -2.19730445e+02]\n [-6.41882263e+00 -1.08793626e+01 -2.57519208e+02  8.71115595e+02\n  -5.34787737e+02 -4.87577959e+00  5.51933577e+01 -5.46444348e+01\n   2.84501003e+02 -1.06461630e+03  7.08210691e+02]\n [ 2.42916232e+01  4.28979890e+01  9.51056519e+02 -3.68517605e+03\n   2.40961445e+03  2.11319352e+01 -2.58639093e+02  2.64753928e+02\n  -1.06461630e+03  4.52970145e+03 -3.18203495e+03]\n [-1.34233224e+01 -2.98599239e+01 -6.20920958e+02  2.58044027e+03\n  -1.82566470e+03 -1.44031168e+01  1.90401649e+02 -2.19730445e+02\n   7.08210691e+02 -3.18203495e+03  2.39778894e+03]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-fa0941eb4726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_nomask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-fa0941eb4726>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(samples, mu_mask, mu_nomask, sigma)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfv_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbayes_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_nomask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-fa0941eb4726>\u001b[0m in \u001b[0;36mbayes_rule\u001b[0;34m(z, mu_mask, mu_nomask, sigma)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# returns 1 if mask, 0 if no mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbayes_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_nomask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mprob_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprob_nomask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_nomask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprob_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mprob_nomask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-fa0941eb4726>\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(z, mu, sigma)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifference_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifference_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdifference_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msecond_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdifference_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdifference_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_term\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msecond_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "\n",
    "# Multivariate Gaussian PDF\n",
    "# TODO: fix\n",
    "def pdf(z, mu, sigma):\n",
    "    first_term = 1 / ((2 * math.pi) ** 0.5) * (np.linalg.det(sigma) ** 0.5)\n",
    "    difference_vector = np.reshape(z - mu, (1, mu.shape[0]))\n",
    "    second_term = math.exp(-0.5 * difference_vector.T * np.linalg.inv(sigma) * difference_vector)\n",
    "    return first_term * second_term\n",
    "\n",
    "# BAYES RULE\n",
    "# p(y = 1|x) = (p(x|y = 1) * p(y = 1) / p(x))\n",
    "# where:    p(y = 1) is our prior phi\n",
    "#           p(x|y = 1) is pdf(x, mu for y = 1, sigma)\n",
    "#           p(x) is constant and equal for both classes, so we can disregard it\n",
    "\n",
    "# returns 1 if mask, 0 if no mask\n",
    "def bayes_rule(z, mu_mask, mu_nomask, sigma):\n",
    "    prob_mask = pdf(z, mu_mask, sigma)\n",
    "    prob_nomask = pdf(z, mu_nomask, sigma)\n",
    "    return prob_mask > prob_nomask\n",
    "\n",
    "# expects samples to be in format [[[...image...], class], ...]\n",
    "def accuracy(samples, mu_mask, mu_nomask, sigma):\n",
    "    correct = 0\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        fv = fv_numpy(sample[0])\n",
    "        correct += bayes_rule(fv, mu_mask, mu_nomask, sigma) == sample[1]\n",
    "    return correct, correct / samples.shape[0]\n",
    "\n",
    "def prepare_samples(mask_images, nomask_images):\n",
    "    samples = []\n",
    "    for image in mask_images:\n",
    "        samples.append(np.array([image, 1], dtype=object))\n",
    "    for image in nomask_images:\n",
    "        samples.append(np.array([image, 0], dtype=object))\n",
    "    return np.array(samples)\n",
    "\n",
    "concat_samples = prepare_samples(mask_imgs, nomask_imgs)\n",
    "print(concat_samples.shape)\n",
    "print(concat_samples[0])\n",
    "print(accuracy(concat_samples, mu_mask, mu_nomask, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Cross-validation\n",
    "\n",
    "**Task 6** (10%): Implement 10-fold cross-validation and report the quality of your results in terms of accuracy and f-score.\n",
    "\n",
    "You have so far trained and tested your classifier on the same data. This does not tell us much about the true performance on unseen data. \n",
    "Instead, you should now randomly split your data into _k_ folds of equal size. you then train your model _k_ times, using all but the _k_'th fold for training and the _k_'th fold for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(80, 2)\n"
     ]
    }
   ],
   "source": [
    "all_samples = prepare_samples(mask_imgs, nomask_imgs)\n",
    "shuffled_samples = np.copy(all_samples)\n",
    "np.random.shuffle(shuffled_samples)\n",
    "print(shuffled_samples.shape)\n",
    "im.fromarray(shuffled_samples[0, 0]).show()\n",
    "\n",
    "def k_fold_cross_validation(samples, k):\n",
    "    counts = []\n",
    "    accs = []\n",
    "    individual_folds = np.array_split(samples, k)\n",
    "    for index, fold in enumerate(individual_folds):\n",
    "        # remove validation fold from training\n",
    "        train = np.delete(individual_folds, index, 0)\n",
    "        val = fold\n",
    "\n",
    "        # split into mask and non mask images\n",
    "        mask_imgs = np.array([sample[0] for sample in train if sample[1] == 1])\n",
    "        nomask_imgs = np.array([sample[0] for sample in train if sample[1] == 0])\n",
    "\n",
    "        # calculate mu, sigma, ... for train\n",
    "        mu_mask = calc_mu_numpy(mask_imgs)\n",
    "        mu_nomask = calc_mu_numpy(nomask_imgs)\n",
    "        sigma = calc_sigma_numpy(mask_imgs, nomask_imgs, mu_mask, mu_nomask)\n",
    "\n",
    "        # test on validation fold\n",
    "        results = accuracy(val, mu_mask, mu_nomask, sigma)\n",
    "        counts.append(results[0])\n",
    "        accs.append(results[1])\n",
    "        \n",
    "    mean_count = np.mean(np.array(counts))\n",
    "    mean_acc = np.mean(np.array(accs))\n",
    "    return mean_count, mean_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature importance\n",
    "\n",
    "**Task 7** (10%): Experiment with the features: how well does the classifier perform with individual features, what is the additional value of the second best feature in addition to the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overwrite feature vector method with different single features\n",
    "# call k_fold_cross_validation for each feature\n",
    "# compare\n",
    "# overwrite fv with best & second best feature, validate, compare to only single best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Report Submission\n",
    "\n",
    "Prepare a report of your solution as a commented Jupyter notebook (using markdown for your results and comments); include figures and results.\n",
    "If you must, you can also upload a PDF document with the report annexed with your Python code.\n",
    "\n",
    "Upload your report file to the Machine Learning Moodle Course page. Please make sure that your submission team corresponds to the team's Moodle group that you're in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd0b26a19bd2e80a295d93b9c279d2e5c53e7eab4d92e561a7637ff5053bd657605",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}